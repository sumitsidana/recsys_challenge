\documentclass{article}

\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\begin{document}
\title{RecSys Challenge 2016}
% \author{Sumit Sidana}
\date{\today}
\maketitle
\section{Data Stats}
\begin{itemize}
 \item \#users who were displayed at least one impression: 2755168
 \item \#Users who did \textbf{at least} one click: 522535
\end{itemize}

\section{One interesting observation}
Field by the name: ``active\_during\_test''
It is waste to recommend those items which have ''active\_during\_test = 0`` because the items are no longer active during the test week. But does that mean we don't train on them and drop 
them? Nope because score further drops down (I checked!). So it is important to train on them because they give us important signals about users but while testing we do not test on them.
\section{Most Popular Approach}

\begin{algorithm}
\caption{Evaluation Using Mean Squared Error}
% \label{alg:tmatam}
\begin{algorithmic}[1] 
\State Filter out columns which have ``Interaction type = 4''
\State Change all the interaction types to ``1'' columns which have
\State group by $item_{id}$ and reverse sort
\end{algorithmic}
\end{algorithm}
Score: 43278.55

\section{Active Popular Items}
\begin{itemize}
 \item Again take 30 most popular items
 \item But this time take active\_during\_test = 1 into account
 \item For each user predict 30 most popular active items
 \item Score: 73253.63 	
\end{itemize}

\section{Matrix Factorization Using ALS of SPARK}
\begin{itemize}
 \item Number of Latent features in both items and users: 10
 \item Number of iterations: 10
 \item Score is Surpisingly low:  15550.28
\end{itemize}

\section{Matrix Factorization Using ALS of SPARK}
\begin{itemize}
 \item Number of Latent features in both items and users: 100
 \item Number of iterations: 100
 \item Number of predicted items for each user: 100
 \item Score:  25429.54.28
 \item Score (active): 38646.14
 \item This can serve as matrix-factorization baseline
 \item FileName: als\_v2
 \item Pro's:
 \begin{itemize}
 \item Can now combine this along with content based approach
 \end{itemize}
 
\end{itemize}

\section{Matrix Factorization Using ALS of SPARK}

\begin{itemize}
 \item Number of Latent features in both items and users: 100
 \item Number of iterations: 100
 \item Number of predicted items for each user: 100
 \item Combined with interesting observation
 \item Score:  38646.14
 \item This can serve as matrix-factorization baseline
 \item FileName: als\_v2\_1
 \item Pro's:
 \begin{itemize}
 \item Can now combine this along with content based approach after predicting 1000 items
 \end{itemize}
 
\end{itemize}

\section{Matrix Factorization in Python3 using SGD}
\begin{itemize}
\item Again number of latent features in both items and users: 10
\item Learning rate of sgd: 0.0005
\item No regularization
\item But taking care of our observation
 \item Number of Latent features in both items and users: 10
 \item Number of iterations: 10 
 \item Score: 14808.21
 \item Surprisingly, all predicted items were same, some bug?
\end{itemize}


\section{Personalized Activeness Popularity}
\begin{itemize}
 \item Sort items by taking into account users's past interactions
 \item Recommend by sorting into descending order
 \item Take into account active\_during\_test = 1
 \item Recommend at least 30 items by completing the list on the basis of popularity
 \item Score: 287524.88
\end{itemize}

 \section{Further Ideas}
 \begin{itemize}
  \item Cross Validation
  \item Increase number of iterations, Increase number of latent factors
  \item Normalize rating between 1 and 5
  \item Regularization
  \item Hybridize between matrix factorization and content fitering and popularity
  \item Weighting the interactions
 \end{itemize}

% \end{itemize}
\end{document}